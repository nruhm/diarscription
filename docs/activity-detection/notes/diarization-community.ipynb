{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81807a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:47: UserWarning: \n",
      "torchcodec is not installed correctly so built-in audio decoding will fail. Solutions are:\n",
      "* use audio preloaded in-memory as a {'waveform': (channel, time) torch.Tensor, 'sample_rate': int} dictionary;\n",
      "* fix torchcodec installation. Error message was:\n",
      "\n",
      "Could not load libtorchcodec. Likely causes:\n",
      "          1. FFmpeg is not properly installed in your environment. We support\n",
      "             versions 4, 5, 6 and 7.\n",
      "          2. The PyTorch version (2.8.0+cpu) is not compatible with\n",
      "             this version of TorchCodec. Refer to the version compatibility\n",
      "             table:\n",
      "             https://github.com/pytorch/torchcodec?tab=readme-ov-file#installing-torchcodec.\n",
      "          3. Another runtime dependency; see exceptions below.\n",
      "        The following exceptions were raised as we tried to load libtorchcodec:\n",
      "        \n",
      "[start of libtorchcodec loading traceback]\n",
      "FFmpeg version 7: Could not find module 'C:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchcodec\\libtorchcodec_core7.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "FFmpeg version 6: Could not find module 'C:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchcodec\\libtorchcodec_core6.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "FFmpeg version 5: Could not find module 'C:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchcodec\\libtorchcodec_core5.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "FFmpeg version 4: Could not find module 'C:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchcodec\\libtorchcodec_core4.dll' (or one of its dependencies). Try using the full path with constructor syntax.\n",
      "[end of libtorchcodec loading traceback].\n",
      "  warnings.warn(\n",
      "c:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "c:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\inspect.py:1020: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n"
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(\n",
    "    \"pyannote/speaker-diarization-community-1\", \n",
    "    token=\"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\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4651a754",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AudioDecoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m output = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mTest1.wav\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyannote\\audio\\core\\pipeline.py:440\u001b[39m, in \u001b[36mPipeline.__call__\u001b[39m\u001b[34m(self, file, **kwargs)\u001b[39m\n\u001b[32m    436\u001b[39m     file = ProtocolFile(file, lazy=\u001b[38;5;28mself\u001b[39m.preprocessors)\n\u001b[32m    438\u001b[39m \u001b[38;5;66;03m# send file duration to telemetry as well as\u001b[39;00m\n\u001b[32m    439\u001b[39m \u001b[38;5;66;03m# requested number of speakers in case of diarization\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m \u001b[43mtrack_pipeline_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply(file, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyannote\\audio\\telemetry\\metrics.py:152\u001b[39m, in \u001b[36mtrack_pipeline_apply\u001b[39m\u001b[34m(pipeline, file, num_speakers, min_speakers, max_speakers, **kwargs)\u001b[39m\n\u001b[32m    150\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_metrics_enabled():\n\u001b[32m    151\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyannote\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mio\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Audio\n\u001b[32m--> \u001b[39m\u001b[32m152\u001b[39m     duration: \u001b[38;5;28mfloat\u001b[39m = \u001b[43mAudio\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_duration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    154\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpyannote\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maudio\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipelines\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdiarization\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m set_num_speakers\n\u001b[32m    155\u001b[39m     num_speakers, min_speakers, max_speakers = set_num_speakers(\n\u001b[32m    156\u001b[39m         num_speakers=num_speakers,\n\u001b[32m    157\u001b[39m         min_speakers=min_speakers,\n\u001b[32m    158\u001b[39m         max_speakers=max_speakers,\n\u001b[32m    159\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:273\u001b[39m, in \u001b[36mAudio.get_duration\u001b[39m\u001b[34m(self, file)\u001b[39m\n\u001b[32m    270\u001b[39m     sample_rate = file[\u001b[33m\"\u001b[39m\u001b[33msample_rate\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m frames / sample_rate\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m metadata: AudioStreamMetadata = \u001b[43mget_audio_metadata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m metadata.duration_seconds_from_header\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\nathanjruhmann\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:86\u001b[39m, in \u001b[36mget_audio_metadata\u001b[39m\u001b[34m(file)\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_audio_metadata\u001b[39m(file: AudioFile) -> \u001b[33m\"\u001b[39m\u001b[33mAudioStreamMetadata\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     71\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Protocol preprocessor used to cache audio metadata\u001b[39;00m\n\u001b[32m     72\u001b[39m \n\u001b[32m     73\u001b[39m \u001b[33;03m    This is useful to speed future random access to this file, e.g.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     83\u001b[39m \u001b[33;03m        Audio file metadata\u001b[39;00m\n\u001b[32m     84\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m     metadata = \u001b[43mAudioDecoder\u001b[49m(file[\u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m]).metadata\n\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m# rewind if needed\u001b[39;00m\n\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(file[\u001b[33m\"\u001b[39m\u001b[33maudio\u001b[39m\u001b[33m\"\u001b[39m], IOBase):\n",
      "\u001b[31mNameError\u001b[39m: name 'AudioDecoder' is not defined"
     ]
    }
   ],
   "source": [
    "output = pipeline(\"Test1.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108be8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for turn, speaker in output.speaker_diarization:\n",
    "    print(f\"{speaker} speaks between t={turn.start:.3f}s and t={turn.end:.3f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
